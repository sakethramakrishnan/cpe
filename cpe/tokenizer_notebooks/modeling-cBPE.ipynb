{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c85ebf-94fd-4057-abd4-138f2d96584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bba048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -iopython (/lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -iopython (/lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from accelerate) (1.13.1)\n",
      "Requirement already satisfied: pyyaml in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: wheel in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (66.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -iopython (/lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: accelerate\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -iopython (/lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed accelerate-0.21.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -iopython (/lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -iopython (/lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -iopython (/lambda_stor/homes/abrace/.conda/envs/genslm_eval/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292c2ae0-ff55-46a6-83f6-28655ace02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import accelerate\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BertConfig, BertForMaskedLM\n",
    "\n",
    "\n",
    "from genslm.utils import read_fasta, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971a9393-68bc-4b42-94af-b2c1bc1811ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence pre-processing helpers\n",
    "\n",
    "# Assign a unique character to each codon so that we can use it as an\n",
    "# input token to a BPE tokenizer. This implements a codon-pair encoding.\n",
    "CODON_CHAR = {\n",
    "    \"TCG\": \"A\",\n",
    "    \"GCA\": \"B\",\n",
    "    \"CTT\": \"C\",\n",
    "    \"ATT\": \"D\",\n",
    "    \"TTA\": \"E\",\n",
    "    \"GGG\": \"F\",\n",
    "    \"CGT\": \"G\",\n",
    "    \"TAA\": \"H\",\n",
    "    \"AAA\": \"I\",\n",
    "    \"CTC\": \"J\",\n",
    "    \"AGT\": \"K\",\n",
    "    \"CCA\": \"L\",\n",
    "    \"TGT\": \"M\",\n",
    "    \"GCC\": \"N\",\n",
    "    \"GTT\": \"O\",\n",
    "    \"ATA\": \"P\",\n",
    "    \"TAC\": \"Q\",\n",
    "    \"TTT\": \"R\",\n",
    "    \"TGC\": \"S\",\n",
    "    \"CAC\": \"T\",\n",
    "    \"ACG\": \"U\",\n",
    "    \"CCC\": \"V\",\n",
    "    \"ATC\": \"W\",\n",
    "    \"CAT\": \"X\",\n",
    "    \"AGA\": \"Y\",\n",
    "    \"GAG\": \"Z\",\n",
    "    \"GTG\": \"a\",\n",
    "    \"GGT\": \"b\",\n",
    "    \"GCT\": \"c\",\n",
    "    \"TTC\": \"d\",\n",
    "    \"AAC\": \"e\",\n",
    "    \"TAT\": \"f\",\n",
    "    \"GTA\": \"g\",\n",
    "    \"CCG\": \"h\",\n",
    "    \"ACA\": \"i\",\n",
    "    \"CGA\": \"j\",\n",
    "    \"TAG\": \"k\",\n",
    "    \"CTG\": \"l\",\n",
    "    \"GGA\": \"m\",\n",
    "    \"ATG\": \"n\",\n",
    "    \"TCT\": \"o\",\n",
    "    \"CGG\": \"p\",\n",
    "    \"GAT\": \"q\",\n",
    "    \"ACC\": \"r\",\n",
    "    \"GAC\": \"s\",\n",
    "    \"GTC\": \"t\",\n",
    "    \"TGG\": \"u\",\n",
    "    \"CCT\": \"v\",\n",
    "    \"GAA\": \"w\",\n",
    "    \"TCA\": \"x\",\n",
    "    \"CAA\": \"y\",\n",
    "    \"AAT\": \"z\",\n",
    "    \"ACT\": \"0\",\n",
    "    \"GCG\": \"1\",\n",
    "    \"GGC\": \"2\",\n",
    "    \"CTA\": \"3\",\n",
    "    \"AAG\": \"4\",\n",
    "    \"AGG\": \"5\",\n",
    "    \"CAG\": \"6\",\n",
    "    \"AGC\": \"7\",\n",
    "    \"CGC\": \"8\",\n",
    "    \"TTG\": \"9\",\n",
    "    \"TCC\": \"!\",\n",
    "    \"TGA\": \"@\",\n",
    "    \"XXX\": \"*\"\n",
    "}\n",
    "\n",
    "\n",
    "def group_and_contextualize(seq: str, k: int = 3):\n",
    "    grouped_codons = \" \".join(seq[i : i + k] for i in range(0, len(seq), k)).upper()\n",
    "    # Removes all modulo 3 chars\n",
    "    return \"\".join(CODON_CHAR.get(codon, \"\") for codon in grouped_codons.split())\n",
    "\n",
    "\n",
    "def decode_grouped_context(seq: str, sep: str = \" \"):\n",
    "    return sep.join(CHAR_CODON[elem] for elem in seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0756c493-5be0-4006-82ce-038350a207ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    config: BertConfig, train_args: TrainingArguments, tokenizer, dataset, data_collator\n",
    "):\n",
    "    # Build model\n",
    "    model = BertForMaskedLM(config)\n",
    "    model_size = sum(t.numel() for t in model.parameters())\n",
    "    print(f\"BERT size: {model_size/1000**2:.1f}M parameters\")\n",
    "\n",
    "    # Build trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=train_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"test\"],\n",
    "    )\n",
    "\n",
    "    # train\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af7444-211a-4ae8-a91d-10849f8821b3",
   "metadata": {},
   "source": [
    "# Vocab size 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1e544b-e98c-4bce-90a6-53a907deabbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "mdh-codon-bpe-vs50257 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/genslm_eval/lib/python3.9/site-packages/transformers/utils/hub.py:687\u001b[0m, in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/.conda/envs/genslm_eval/lib/python3.9/site-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/genslm_eval/lib/python3.9/site-packages/transformers/utils/hub.py:495\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    494\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mhead(url, headers\u001b[38;5;241m=\u001b[39mheaders, allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout)\n\u001b[0;32m--> 495\u001b[0m \u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m etag \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Linked-Etag\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/genslm_eval/lib/python3.9/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# The repo was not found and the user is not Authenticated\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m401 Client Error: Repository not found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the repo is private, make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    422\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error: Repository not found for url: https://huggingface.co/mdh-codon-bpe-vs50257/resolve/main/tokenizer_config.json. If the repo is private, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setup Tokenizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m special_tokens \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munk_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[UNK]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[CLS]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meos_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[EOS]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     }\n\u001b[0;32m---> 12\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mPreTrainedTokenizerFast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmdh-codon-bpe-vs50257\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39madd_special_tokens(special_tokens)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/genslm_eval/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1675\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vocab_files_target:\n\u001b[1;32m   1673\u001b[0m     \u001b[38;5;66;03m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m     fast_tokenizer_file \u001b[38;5;241m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[0;32m-> 1675\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mget_file_from_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(resolved_config_file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m reader:\n",
      "File \u001b[0;32m~/.conda/envs/genslm_eval/lib/python3.9/site-packages/transformers/utils/hub.py:698\u001b[0m, in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    687\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m cached_path(\n\u001b[1;32m    688\u001b[0m         resolved_file,\n\u001b[1;32m    689\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m         use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token,\n\u001b[1;32m    695\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: mdh-codon-bpe-vs50257 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "# Setup Tokenizer\n",
    "special_tokens = {\n",
    "    \"unk_token\": \"[UNK]\",\n",
    "    \"cls_token\": \"[CLS]\",\n",
    "    \"sep_token\": \"[SEP]\",\n",
    "    \"pad_token\": \"[PAD]\",\n",
    "    \"mask_token\": \"[MASK]\",\n",
    "    \"bos_token\": \"[BOS]\",\n",
    "    \"eos_token\": \"[EOS]\",\n",
    "}\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"mdh-codon-bpe-vs50257\")\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300c3f5-906b-4c89-bf6f-fc047746e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "sequence_file = Path(\n",
    "    \"/lambda_stor/homes/khippe/genslm_foundation/genome_data/mdh_sc23/fasta/mdh_natural_sequences.ffn\"\n",
    ")\n",
    "sequences = read_fasta(sequence_file)\n",
    "\n",
    "\n",
    "dataset_seqs = [group_and_contextualize(seq.sequence) for seq in sequences]\n",
    "tokenized_seqs = tokenizer(\n",
    "    dataset_seqs,\n",
    "    max_length=1024,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"input_ids\": tokenized_seqs.input_ids.tolist(),\n",
    "    \"attention_mask\": tokenized_seqs.attention_mask.tolist(),\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset = dataset.train_test_split(test_size=0.05)\n",
    "print(dataset)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a075dd0-ae12-4bbd-bbde-3f400bafeb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "\n",
    "# 50m params\n",
    "config = BertConfig(\n",
    "    hidden_size=512,\n",
    "    num_hidden_layers=8,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=2048,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_position_embeddings=1024,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"mdh-cBPE-BERT-50m\",\n",
    "    per_device_train_batch_size=28,\n",
    "    per_device_eval_batch_size=28,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    logging_steps=25,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=500,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "train_model(config, args, tokenizer, dataset, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46c861-1ff2-47b4-b9bd-b035e1dfb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "\n",
    "# 125m params\n",
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_position_embeddings=1024,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"mdh-cBPE-BERT-125m\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    logging_steps=25,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=500,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "train_model(config, args, tokenizer, dataset, data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83cf5c3-5679-4e4a-af99-f52572f9371d",
   "metadata": {},
   "source": [
    "# Vocab Size 30,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0234e487-2bdf-4678-a4d8-643fb4c90d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tokenizer\n",
    "special_tokens = {\n",
    "    \"unk_token\": \"[UNK]\",\n",
    "    \"cls_token\": \"[CLS]\",\n",
    "    \"sep_token\": \"[SEP]\",\n",
    "    \"pad_token\": \"[PAD]\",\n",
    "    \"mask_token\": \"[MASK]\",\n",
    "    \"bos_token\": \"[BOS]\",\n",
    "    \"eos_token\": \"[EOS]\",\n",
    "}\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"mdh-codon-bpe-vs30000\")\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0418ebb-8bab-4305-906c-e3962ee0f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 34799\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 1832\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "sequence_file = Path(\n",
    "    \"/lambda_stor/homes/khippe/genslm_foundation/genome_data/mdh_sc23/fasta/mdh_natural_sequences.ffn\"\n",
    ")\n",
    "sequences = read_fasta(sequence_file)\n",
    "\n",
    "\n",
    "dataset_seqs = [group_and_contextualize(seq.sequence) for seq in sequences]\n",
    "tokenized_seqs = tokenizer(\n",
    "    dataset_seqs,\n",
    "    max_length=256,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"input_ids\": tokenized_seqs.input_ids.tolist(),\n",
    "    \"attention_mask\": tokenized_seqs.attention_mask.tolist(),\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset = dataset.train_test_split(test_size=0.05)\n",
    "print(dataset)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f0bdcf4-a0dd-4daa-9804-c5967c70d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 5,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT size: 41.0M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "/home/khippe/miniconda3/envs/genslm-develop/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 34799\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 28\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 56\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 6210\n",
      "  Number of trainable parameters = 41005872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6210' max='6210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6210/6210 13:43, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>10.236500</td>\n",
       "      <td>10.130811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.748200</td>\n",
       "      <td>9.586514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>9.264400</td>\n",
       "      <td>9.145963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.011800</td>\n",
       "      <td>8.973907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>8.914700</td>\n",
       "      <td>8.877105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.824900</td>\n",
       "      <td>8.754184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>8.722600</td>\n",
       "      <td>8.658297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.624300</td>\n",
       "      <td>8.570626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>8.525200</td>\n",
       "      <td>8.464322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.457700</td>\n",
       "      <td>8.387164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>8.387400</td>\n",
       "      <td>8.305061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.288700</td>\n",
       "      <td>8.182940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>8.190700</td>\n",
       "      <td>8.131498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>8.145100</td>\n",
       "      <td>8.070731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>8.076100</td>\n",
       "      <td>8.007638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.040900</td>\n",
       "      <td>7.966458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>7.955300</td>\n",
       "      <td>7.929960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>7.925800</td>\n",
       "      <td>7.846315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>7.874900</td>\n",
       "      <td>7.806855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.809600</td>\n",
       "      <td>7.761829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>7.785100</td>\n",
       "      <td>7.705748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>7.728700</td>\n",
       "      <td>7.698399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>7.684900</td>\n",
       "      <td>7.607269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.654500</td>\n",
       "      <td>7.584404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>7.774700</td>\n",
       "      <td>7.553535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>7.541900</td>\n",
       "      <td>7.553792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>7.548400</td>\n",
       "      <td>7.514333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>7.482000</td>\n",
       "      <td>7.453316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>7.477500</td>\n",
       "      <td>7.446789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.413100</td>\n",
       "      <td>7.407442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>7.407600</td>\n",
       "      <td>7.371354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>7.350400</td>\n",
       "      <td>7.368821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>7.349000</td>\n",
       "      <td>7.313973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.254647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>7.253900</td>\n",
       "      <td>7.196935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>7.216723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>7.165600</td>\n",
       "      <td>7.158910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>7.137900</td>\n",
       "      <td>7.120793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>7.062000</td>\n",
       "      <td>7.113492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.102000</td>\n",
       "      <td>7.049465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>7.043400</td>\n",
       "      <td>7.033835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>7.038700</td>\n",
       "      <td>7.008572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>7.006200</td>\n",
       "      <td>6.988341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>6.961800</td>\n",
       "      <td>6.933130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>6.950500</td>\n",
       "      <td>6.930651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>6.901400</td>\n",
       "      <td>6.901619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>6.895200</td>\n",
       "      <td>6.853166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>6.848900</td>\n",
       "      <td>6.848709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>6.863000</td>\n",
       "      <td>6.820154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>6.931800</td>\n",
       "      <td>6.808672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>6.750300</td>\n",
       "      <td>6.771083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>6.746400</td>\n",
       "      <td>6.756711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>6.718300</td>\n",
       "      <td>6.722734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>6.698200</td>\n",
       "      <td>6.682592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>6.687100</td>\n",
       "      <td>6.673784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.661180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>6.610600</td>\n",
       "      <td>6.600831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>6.636300</td>\n",
       "      <td>6.583382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>6.616500</td>\n",
       "      <td>6.572299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.575400</td>\n",
       "      <td>6.551452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>6.554600</td>\n",
       "      <td>6.511319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>6.513700</td>\n",
       "      <td>6.530736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>6.422400</td>\n",
       "      <td>6.487930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>6.440100</td>\n",
       "      <td>6.464184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>6.416000</td>\n",
       "      <td>6.440678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>6.419300</td>\n",
       "      <td>6.386412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>6.393000</td>\n",
       "      <td>6.411007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>6.380600</td>\n",
       "      <td>6.387681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>6.382800</td>\n",
       "      <td>6.371814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>6.331400</td>\n",
       "      <td>6.309314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>6.300100</td>\n",
       "      <td>6.287512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>6.278400</td>\n",
       "      <td>6.276726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>6.297200</td>\n",
       "      <td>6.297756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>6.260800</td>\n",
       "      <td>6.265937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>6.337200</td>\n",
       "      <td>6.215944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>6.203400</td>\n",
       "      <td>6.233021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>6.140700</td>\n",
       "      <td>6.209322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>6.163400</td>\n",
       "      <td>6.215448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>6.130300</td>\n",
       "      <td>6.184204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>6.100900</td>\n",
       "      <td>6.146004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>6.095600</td>\n",
       "      <td>6.127654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>6.082000</td>\n",
       "      <td>6.114303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>6.077100</td>\n",
       "      <td>6.093286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>6.045700</td>\n",
       "      <td>6.076985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>6.027700</td>\n",
       "      <td>6.048765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>6.014300</td>\n",
       "      <td>6.042115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>6.102900</td>\n",
       "      <td>5.998275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>5.921400</td>\n",
       "      <td>5.983978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>5.959500</td>\n",
       "      <td>5.988403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.947100</td>\n",
       "      <td>5.970993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>5.932600</td>\n",
       "      <td>5.965525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>5.886500</td>\n",
       "      <td>5.929847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>5.884300</td>\n",
       "      <td>5.953277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>5.868600</td>\n",
       "      <td>5.917734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>5.865800</td>\n",
       "      <td>5.899010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>5.880200</td>\n",
       "      <td>5.876630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>5.863900</td>\n",
       "      <td>5.889632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>5.822300</td>\n",
       "      <td>5.829957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>5.855000</td>\n",
       "      <td>5.839855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.837600</td>\n",
       "      <td>5.819363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>5.793800</td>\n",
       "      <td>5.844332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>5.756300</td>\n",
       "      <td>5.838388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>5.769100</td>\n",
       "      <td>5.807581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>5.760400</td>\n",
       "      <td>5.804995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>5.782700</td>\n",
       "      <td>5.786738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>5.762500</td>\n",
       "      <td>5.803213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>5.755500</td>\n",
       "      <td>5.789880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>5.758600</td>\n",
       "      <td>5.773776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>5.738500</td>\n",
       "      <td>5.775069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>5.798700</td>\n",
       "      <td>5.757326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>5.773200</td>\n",
       "      <td>5.752676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>5.835500</td>\n",
       "      <td>5.776118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>5.728700</td>\n",
       "      <td>5.751389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>5.697600</td>\n",
       "      <td>5.752513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>5.697400</td>\n",
       "      <td>5.760121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>5.717300</td>\n",
       "      <td>5.752221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>5.689300</td>\n",
       "      <td>5.742940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>5.760700</td>\n",
       "      <td>5.730121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>5.699700</td>\n",
       "      <td>5.735635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.691500</td>\n",
       "      <td>5.743168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>5.732200</td>\n",
       "      <td>5.720603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>5.697000</td>\n",
       "      <td>5.718484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>5.696500</td>\n",
       "      <td>5.757574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>5.696200</td>\n",
       "      <td>5.763635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-500\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-1000\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-1500\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-1500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-2000\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-2500\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-2500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-3000\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-3500\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-3500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-4000\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-4500\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-4500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-5000\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-5500\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-5500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-50m-vs30000/checkpoint-6000\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-6000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-6000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-50m-vs30000/checkpoint-6000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 41.0M params\n",
    "config = BertConfig(\n",
    "    hidden_size=512,\n",
    "    num_hidden_layers=8,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=2048,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_position_embeddings=256,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"mdh-cBPE-BERT-50m-vs30000\",\n",
    "    per_device_train_batch_size=28,\n",
    "    per_device_eval_batch_size=28,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    logging_steps=25,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=500,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = train_model(config, args, tokenizer, dataset, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041cf195-ca0f-4860-9801-67546074915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 5,\n",
      "  \"eos_token_id\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Using cuda_amp half precision backend\n",
      "/home/khippe/miniconda3/envs/genslm-develop/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 34799\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 28\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 56\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 6210\n",
      "  Number of trainable parameters = 108916272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT size: 108.9M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3062' max='6210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3062/6210 11:45 < 12:06, 4.34 it/s, Epoch 4.93/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>10.194100</td>\n",
       "      <td>10.043712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.540000</td>\n",
       "      <td>9.351885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>9.107400</td>\n",
       "      <td>9.032630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.991900</td>\n",
       "      <td>8.934639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>8.843200</td>\n",
       "      <td>8.778870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.731200</td>\n",
       "      <td>8.636480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>8.618200</td>\n",
       "      <td>8.569446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.529400</td>\n",
       "      <td>8.447598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>8.427200</td>\n",
       "      <td>8.359210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.355300</td>\n",
       "      <td>8.288280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>8.332400</td>\n",
       "      <td>8.314942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.263800</td>\n",
       "      <td>8.231756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>8.219300</td>\n",
       "      <td>8.154346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>8.188000</td>\n",
       "      <td>8.132518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>8.145200</td>\n",
       "      <td>8.073050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.154500</td>\n",
       "      <td>8.068520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>8.083100</td>\n",
       "      <td>8.108434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>8.085000</td>\n",
       "      <td>8.034921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>8.040500</td>\n",
       "      <td>7.975334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.004800</td>\n",
       "      <td>7.961349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>7.992100</td>\n",
       "      <td>7.934486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>7.965700</td>\n",
       "      <td>7.940934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>7.926300</td>\n",
       "      <td>7.873972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.901200</td>\n",
       "      <td>7.843167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>8.033300</td>\n",
       "      <td>7.811506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>7.817600</td>\n",
       "      <td>7.859589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>7.821300</td>\n",
       "      <td>7.797773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>7.746300</td>\n",
       "      <td>7.702338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>7.737300</td>\n",
       "      <td>7.700449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.681100</td>\n",
       "      <td>7.665230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>7.687900</td>\n",
       "      <td>7.627018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>7.632400</td>\n",
       "      <td>7.638674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>7.617400</td>\n",
       "      <td>7.606555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>7.590000</td>\n",
       "      <td>7.558481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>7.557200</td>\n",
       "      <td>7.507568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>7.542400</td>\n",
       "      <td>7.515728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>7.498400</td>\n",
       "      <td>7.457556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>7.467300</td>\n",
       "      <td>7.435393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>7.393200</td>\n",
       "      <td>7.430071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.438200</td>\n",
       "      <td>7.369957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>7.374800</td>\n",
       "      <td>7.370050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>7.370300</td>\n",
       "      <td>7.334554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>7.333800</td>\n",
       "      <td>7.287489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>7.310700</td>\n",
       "      <td>7.309142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>7.287200</td>\n",
       "      <td>7.250685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>7.235000</td>\n",
       "      <td>7.246297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>7.234600</td>\n",
       "      <td>7.166082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>7.186600</td>\n",
       "      <td>7.176658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>7.194200</td>\n",
       "      <td>7.157720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>7.280500</td>\n",
       "      <td>7.179677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>7.101300</td>\n",
       "      <td>7.092632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>7.070100</td>\n",
       "      <td>7.081509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>7.067000</td>\n",
       "      <td>7.066212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>7.061900</td>\n",
       "      <td>7.058714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>7.028500</td>\n",
       "      <td>7.009416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>6.984700</td>\n",
       "      <td>7.007651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>6.958900</td>\n",
       "      <td>6.933809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>6.985500</td>\n",
       "      <td>6.930516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>6.963400</td>\n",
       "      <td>6.919579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.929000</td>\n",
       "      <td>6.901337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>6.916600</td>\n",
       "      <td>6.868036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-125m-vs30000/checkpoint-500\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-125m-vs30000/checkpoint-1000\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-125m-vs30000/checkpoint-1500\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-1500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-125m-vs30000/checkpoint-2000\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-125m-vs30000/checkpoint-2500\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2500/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2500/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-2500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n",
      "Saving model checkpoint to mdh-cBPE-BERT-125m-vs30000/checkpoint-3000\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-3000/config.json\n",
      "Configuration saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-3000/generation_config.json\n",
      "Model weights saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in mdh-cBPE-BERT-125m-vs30000/checkpoint-3000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1832\n",
      "  Batch size = 28\n"
     ]
    }
   ],
   "source": [
    "# 108.9M params\n",
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_position_embeddings=256,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"mdh-cBPE-BERT-125m-vs30000\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    logging_steps=25,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=500,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = train_model(config, args, tokenizer, dataset, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e697cf8e-0265-49ff-8a2e-721cc3cb2ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1d2b8a7f7e8b4294e58905fa61be7044a6603711006b6ad534d224b83be168b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
